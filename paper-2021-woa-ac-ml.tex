%% The first command in your LaTeX source must be the \documentclass command.
%%
%% Options:
%% twocolumn : Two column layout.
%% hf: enable header and footer.
\documentclass[
twocolumn,
% hf,
]{ceurart}
\usepackage[colorinlistoftodos,prependcaption]{todonotes}
\usepackage{xcolor}
%%
%% One can fix some overfulls
\sloppy

\newcommand{\meta}[1]{{\color{blue}#1}}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% Rights management information.
%% CC-BY is default license.
\copyrightyear{2020}
\copyrightclause{Copyright for this paper by its authors.
  Use permitted under Creative Commons License Attribution 4.0
  International (CC BY 4.0).}

%%
%% This command is for the conference information
\conference{22nd Workshop "From Objects to Agents" 
Bologna, Italy, 1-3 September 2021 }

%%
%% The "title" command
\title{Towards a Machine Learning approach for Aggregate Computing} %% or Towards a Machine Learning approach for Aggregate Computing

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
\author[1]{Gianluca Aguzzi}[%
orcid=todo,
email=gianluca.aguzzi@unibo.it,
url=https://todo/,
]
\author[2]{Roberto Casadei}[%
orcid=todo,
email=roby.casadei@unibo.it,
url=todo,
]
\author[2]{Mirko Viroli}[%
orcid=todo,
email=mirko.viroli@unibo.it,
url=todo,
]
\address[1]{Alma Mater Studiorum - Universit√† di Bologna,
  Cesena, Italy}
%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Artificial intelligence is here to stay. 
  In particular, Deep Learning techniques in the last years outperform hand-craft human solutions in different contexts, ranging from computer vision to videogames.
  Currently, though, an all-encompassing Deep learning model does not exist, so researchers explore the possibility to apply these outstanding techniques in different fields.
  One of the most challenging is Collective-Adaptive System (CAS). Here, engineers have to handle large scale, global-to-local behaviour mapping,
  highly environment stochasticity. 
  Historically, researchers favour handling them with self-organisation, by which a collective behaviour emerges from continuously local interaction between simple components.
  A novel technique to specify self-organising behaviour in a composable and functional manner is Aggregate Computing. Even though is promising for expressing high-level collective behaviour, 
  it needs to build low-level blocks that tend to be tricky. 
  On the opposite side, some research lines apply Deep learning (supervised, reinforcement, non-supervised and self-supervised)
  along with CAS. Currently, though, no one gain popularity and solution tend to be application-specific.
  So, we outline a Machine Learning technique that could be applied in Aggregate Computing, making the possibility to combine declarative and automatic approaches that can easily scale in application complexity.
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\begin{keywords}
  Collective-Adaptive System \sep
  Aggregate Computing \sep
  Deep Learning \sep
  Reinforcement Learning \sep
\end{keywords}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\todo[inline, color=red]{max pages : 16}
\section{Introduction}
Aggregate Computing~\cite{DBLP:journals/computer/BealPV15}
\todo[inline]{walkthrogh CAS, why they are hard}
Nowadays, computer engineers have to deal with Collective Adaptive Systems (CASs) due to the increasing interconnected computational devices placed in ever-changing environments.
 Examples of those include robot swarm, smart cities and augmenting crowds.
A CAS is characterised by 
\begin{itemize}
\item a global order that emerges from local node interactions, 
\item  decentralised control, and 
\item adaptive behaviours towards environmental changes to pursuit a collective goal.
\end{itemize}
CAS are notoriously hard to design due as part of complex systems. 
%
So, over the years, in literature, various approaches aim at handling this complexity. 
%
Some of them take inspiration from the natural system composed of social animals -- like bees, fish and ants. 
%
Here, a sort of hive mind arises -- something referred to as swarm intelligence -- born from local interactions between agents. 
%
This kind of behaviour is called self-organisation, namely a global order that emerges from continuous interactions between simple entities.

Initially, researchers try to bring those properties in the computer science world by miming the collective behaviour bottom-up, 
 namely trying to find the single node behaviour to reach a global behaviour, e.g. flocking, foraging, etc.
%
Though, this mapping isn't easily definable -- since we handle complex systems -- therefore novel techniques move the design focus by the ensemble level,
 specifying the system behaviour as a whole. 

\todo[inline]{Brief description of declarative approaches, pros and cons}
\todo[inline]{Brief description of machine learning approaches (MARL and GNN for communication), pros and cons}
\todo[inline]{Declare our direction: Combination to declarative and automatic approach}
\todo[inline]{Outline}

\section{Background and Related Work}
\todo[inline]{walkthrogh traditional engineering way to design CAS}
\todo[inline]{walkthrogh Aggregate Computing}
\todo[inline]{walkthrogh Machine learning approach applied in MARL}
\todo[inline]{current limitation (application specific, not large scale, centralised in some cases,..)}
\todo[inline]{novel work on GNN -- agent learn to communicate -- node size indipendent~\cite{DBLP:conf/corl/TolstayaGPP0R19}}

\section{Aggregate computing and Machine learning}
\todo[inline]{description of execution model of AC}
\todo[inline]{typical structure of AC algorithm : time evolution with hood operation}
\todo[inline]{show an example of block G?}
\todo[inline]{declare problems in applying traditional approach (variable-input size, feature hard-coded, environment non-stationarity, reward only know at the end)}
\todo[inline]{define benefit, possible contrast (i.e. if AC is declarative, why we should use ML?)}

In this section,
 we analyse the characteristics of the aggregate computing paradigm,
 map these to relevant machine learning contributions in literature,
 and summarise the analysis into a roadmap.

\paragraph{Multi- and many-agent system}
%
An aggregate system is a multi-agent system
 and, often, a \emph{many}-agent system
 where a large number (hundreds or more)
 of autonomous entities are programmed to achieve 
 some collective behaviour by means of \emph{repeated} 
 sensing, computation, communication, and actuation steps.
%
Due to the high stochasticity of the environment,
 it is almost impossible to know and
 program the optimal behaviour for all agents in advance.
 This results in the need to create intelligent agents
 so that they can learn the optimal behaviour and adapt to environmental changes.
%
In recent decades there has been an emerging trend in the use of reinforcement learning
 in multi-agent settings, as a powerful, robust and adaptive learning paradigm.
 Progress has been considerable and a wide range of algorithms are now available.
% to expand and and references
In general, there is not one technical solution in the multi-agent context.
 There are several (even orthogonal) viewpoints on which research has focused.
 One line of research (that of game theory) has tried to find techniques that achieve equilibrium such as Nash-Q learning.
 Others have focused on exploiting coordination between agents. 
 Others have applied single RL (such as Histeric Q-leraning) to each agent and achieved good results (even if no formal proof exist).
%
 The main problem with most of the solutions available in the literature is that they consider a small number of agents (or at least test them on small games).

\meta{TODO present approaches for learning in MAS, e.g., through prominent surveys}

\paragraph{Neighbour-based or indirect (environment-mediated) interaction}
%
In aggregate systems,
 a device can only directly interact with neighbours.
%
Data flows may be implemented
 to support indirect communication across multiple hops;
 however, information from devices far away tends to be obsolete.
%
The environment can also be used, via stigmergy,
 for indirect communication;
 however, a device can typically only access 
  its very local portion of the environment.
%
In other words, the system state is only \emph{partially observable}.
%
\meta{What ML in these kinds of systems?}

\paragraph{Learning goal: collective behaviour}
%
The devices of an aggregate 
 must cooperatively learn the ``aggregate program'',
 namely the collective behaviour 
 that achieves a particular \emph{global goal}
 in a decentralised, resilient way.
%

\paragraph{Self-organisation, swarm robotics}
%
\meta{TODO}

\paragraph{Emergent behaviour}
%
The collective behaviour of an aggregate system
 \emph{emerges} 
 from a dense network of computations and interactions
 in an evolving environment.
%

\paragraph{Delayed, global rewards}
%
In the light of the above properties,
 if we consider a learning approach based on rewards,
 we must observe that such rewards would be
 delayed and mostly global---i.e.,
 it may not be easy to solve the credit-assignment problem
 to distinguish good from bad individual contributions
 to the global outcome.

\paragraph{Transient phase}
%
When an aggregate behaviour is carried out,
 we often focus on the stabilised outcomes,
 tolerating outcomes that are being generated
 during the transient phase.
%
However, intermediate results are often important,
 and invariants should hold throughout the entire computation.

\paragraph{Dynamic topology}
%
If we admit \emph{mobility} and \emph{failure},
 then we must also consider 
 the possibility of changes in neighbourhoods
 and hence the need of dealing with dynamic topologies.


\subsection{Roadmap}

\section{Towards Machine Learning approaches}
\todo[inline]{declare inspiration of GNN} %%ideally, we should use either reinforcement and supervised learning
\todo[inline]{show the structure: state network, neighbour network, output network}
\todo[inline]{possible limitations: non stabilisation and asynchrnous evaluation}
\todo[inline]{learning algorithm: how to apply backprop here (similar to truncated backpropagation, currently does not work)}
\todo[inline]{when makes sense to apply RL? (goal-oriented application?)}
\section{Evaluation} %% optional section
\todo[inline]{define experiment setup}
\todo[inline]{verify if the system perform as traditional method}

\section{Conclusion and Future Work}
\todo[inline]{sharping the model}
\todo[inline]{tune network in order to outperform traditional method}
\todo[inline]{engineering hybrid application (when we need to use ML)}
\todo[inline]{toward online learning?}
%%
%% Define the bibliography file to be used
\bibliography{biblio}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\end{document}

%%
%% End of file
