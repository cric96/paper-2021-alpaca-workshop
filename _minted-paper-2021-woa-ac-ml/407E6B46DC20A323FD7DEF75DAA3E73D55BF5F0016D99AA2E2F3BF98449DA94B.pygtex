\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{rep}\PYG{p}{(}\PYG{n}{initialState}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{n}{oldState} \PYG{o}{=\PYGZgt{}}
  \PYG{k+kd}{val} \PYG{n}{output} \PYG{o}{=} \PYG{n}{rep}\PYG{p}{(}\PYG{n}{inf}\PYG{p}{)} \PYG{p}{\PYGZob{}} \PYG{n}{hopCounts} \PYG{o}{=\PYGZgt{}}
   \PYG{k+kd}{val} \PYG{n}{currentState} \PYG{o}{=} \PYG{n}{state}\PYG{p}{(}\PYG{n}{hopCounts}\PYG{p}{)}
   \PYG{k+kd}{val} \PYG{n}{action} \PYG{o}{=} \PYG{n}{localPolicy}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}
   \PYG{n}{mux}\PYG{p}{(}\PYG{n}{source}\PYG{p}{)}
    \PYG{p}{\PYGZob{}} \PYG{l+m+mi}{0} \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZob{}} \PYG{n}{minHood}\PYG{p}{(}\PYG{n}{hopCounts}\PYG{p}{)} \PYG{o}{+} \PYG{l+m+mi}{1} \PYG{o}{+} \PYG{n}{action}\PYG{p}{\PYGZcb{}}
  \PYG{p}{\PYGZcb{}}
  \PYG{k+kd}{val} \PYG{n}{currentReward} \PYG{o}{=} \PYG{n}{reward}\PYG{p}{(}\PYG{n}{output}\PYG{p}{)}
  \PYG{n}{qLearning}\PYG{p}{(}\PYG{n}{oldState}\PYG{p}{,}
   \PYG{n}{state}\PYG{p}{,}
   \PYG{n}{action}\PYG{p}{,}
   \PYG{n}{reward}
  \PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}
